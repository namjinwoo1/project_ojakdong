#include <ros/ros.h>
#include <ros/package.h>
#include <sensor_msgs/Image.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/opencv.hpp>
#include "darknet.h"

extern "C" {
    #include "darknet.h"
}

class CameraProcessor {
public:
    CameraProcessor() {
        // Darknet 초기화
        std::string packagePath = ros::package::getPath("project_ojakdong");
        std::string configPath = packagePath + "/model/yolov4-tiny.cfg";
        std::string weightsPath = packagePath + "/model/yolov4-tiny.weights";
        std::string classesPath = packagePath + "/model/coco.names";

        net = load_network(const_cast<char*>(configPath.c_str()),
                           const_cast<char*>(weightsPath.c_str()), 0);
        set_batch_network(net, 1);

        loadClasses(classesPath);

        // ROS 설정
        imageSubscriber = nh.subscribe("/usb_cam/image_raw", 1, &CameraProcessor::imageCallback, this);
        imagePublisher = nh.advertise<sensor_msgs::Image>("/processed_image", 1);

        ROS_INFO("CameraProcessor Node Started");
    }

    ~CameraProcessor() {
        if (net) {
            free_network_ptr(net);  // 포인터용 함수로 변경
        }
    }

    void spin() {
        ros::spin();
    }

private:
    ros::NodeHandle nh;
    ros::Subscriber imageSubscriber;
    ros::Publisher imagePublisher;
    network* net;
    std::vector<std::string> classes;

    void loadClasses(const std::string& path) {
        std::ifstream ifs(path.c_str());
        std::string line;
        while (std::getline(ifs, line)) {
            classes.push_back(line);
        }
        ROS_INFO("Loaded %lu classes", classes.size());
    }

    void imageCallback(const sensor_msgs::ImageConstPtr& msg) {
        try {
            cv_bridge::CvImagePtr cvPtr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
            cv::Mat frame = cvPtr->image;

            if (frame.empty()) {
                ROS_ERROR("Received empty frame");
                return;
            }

            // YOLO 입력 변환 및 검출
            std::vector<cv::Rect> boxes;
            std::vector<int> classIds;
            std::vector<float> confidences;

            detectObjects(frame, boxes, classIds, confidences);

            // 검출된 객체 표시
            for (const auto& box : boxes) {
                rectangle(frame, box, cv::Scalar(0, 255, 0), 2); // 초록색 사각형
                putText(frame, "Person", cv::Point(box.x, box.y - 10), cv::FONT_HERSHEY_SIMPLEX, 0.6, cv::Scalar(0, 255, 0), 2);
            }

            // 처리된 이미지를 ROS 메시지로 변환하여 발행
            sensor_msgs::ImagePtr processedMsg = cv_bridge::CvImage(std_msgs::Header(), "bgr8", frame).toImageMsg();
            imagePublisher.publish(processedMsg);
        } catch (const cv_bridge::Exception& e) {
            ROS_ERROR("cv_bridge Exception: %s", e.what());
        }
    }

    void detectObjects(const cv::Mat& frame, std::vector<cv::Rect>& boxes, std::vector<int>& classIds, std::vector<float>& confidences) {
        // YOLO 입력 변환
        image im = mat_to_image(frame);
        network_predict_image(net, im);

        int nboxes = 0;
        detection* dets = get_network_boxes(net, frame.cols, frame.rows, 0.5, 0.4, nullptr, 1, &nboxes, 0);  // `nullptr`와 `letter` 추가

        // 박스 추출
        for (int i = 0; i < nboxes; ++i) {
            for (int j = 0; j < dets[i].classes; ++j) {
                if (dets[i].prob[j] > 0.5 && classes[j] == "person") { // Confidence & 클래스 필터링
                    int left = static_cast<int>((dets[i].bbox.x - dets[i].bbox.w / 2) * frame.cols);
                    int top = static_cast<int>((dets[i].bbox.y - dets[i].bbox.h / 2) * frame.rows);
                    int width = static_cast<int>(dets[i].bbox.w * frame.cols);
                    int height = static_cast<int>(dets[i].bbox.h * frame.rows);

                    boxes.emplace_back(left, top, width, height);
                    classIds.push_back(j);
                    confidences.push_back(dets[i].prob[j]);
                }
            }
        }

        // Non-Maximum Suppression 적용
        std::vector<int> indices;
        cv::dnn::NMSBoxes(boxes, confidences, 0.5, 0.4, indices);

        // 필터링된 박스만 유지
        std::vector<cv::Rect> filteredBoxes;
        std::vector<int> filteredClassIds;
        std::vector<float> filteredConfidences;

        for (int idx : indices) {
            filteredBoxes.push_back(boxes[idx]);
            filteredClassIds.push_back(classIds[idx]);
            filteredConfidences.push_back(confidences[idx]);
        }

        // 결과 반영
        boxes = filteredBoxes;
        classIds = filteredClassIds;
        confidences = filteredConfidences;

        // 메모리 해제
        free_detections(dets, nboxes);
    }


    image mat_to_image(const cv::Mat& mat) {
        int h = mat.rows;
        int w = mat.cols;
        int c = mat.channels();
        image im = make_image(w, h, c);
        for (int y = 0; y < h; ++y) {
            for (int x = 0; x < w; ++x) {
                for (int k = 0; k < c; ++k) {
                    im.data[k * w * h + y * w + x] = mat.at<cv::Vec3b>(y, x)[k] / 255.0;
                }
            }
        }
        return im;
    }
};

int main(int argc, char** argv) {
    ros::init(argc, argv, "camera_processor_node");
    CameraProcessor processor;
    processor.spin();
    return 0;
}

#include <ros/ros.h>
#include <ros/package.h>
#include <sensor_msgs/Image.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/opencv.hpp>
#include "darknet.h"
#include "project_ojakdong/DetectionResult.h"
#include <cuda_runtime.h>

extern "C" {
    #include "darknet.h"
}

class CameraProcessor {
public:
    CameraProcessor() : rate_(15) {  // 초당 15 프레임 제한
        // Darknet 초기화
        std::string packagePath = ros::package::getPath("project_ojakdong");
        std::string configPath = packagePath + "/model/yolov4-tiny.cfg";
        std::string weightsPath = packagePath + "/model/yolov4-tiny.weights";
        std::string classesPath = packagePath + "/model/coco.names";

        net = load_network(const_cast<char*>(configPath.c_str()),
                   const_cast<char*>(weightsPath.c_str()), 0);
        set_batch_network(net, 1);

        gpu_index = 0;                // GPU 인덱스를 0으로 설정
        cuda_set_device(gpu_index);   // CUDA 장치 설정

        // GPU 디바이스 확인
        int deviceCount;
        cudaGetDeviceCount(&deviceCount);
        ROS_INFO("Available CUDA Devices: %d", deviceCount);

        cudaDeviceProp deviceProp;
        cudaGetDeviceProperties(&deviceProp, gpu_index);
        ROS_INFO("Using GPU: %s", deviceProp.name);

        loadClasses(classesPath);

        // ROS 설정
        imageSubscriber = nh.subscribe("/usb_cam/image_raw", 1, &CameraProcessor::imageCallback, this);
        // imageSubscriber = nh.subscribe("/camera/rgb/image_raw", 1, &CameraProcessor::imageCallback, this);  //gazebo카메라
        resultPublisher = nh.advertise<project_ojakdong::DetectionResult>("/detection_result", 1);

        ROS_INFO("CameraProcessor Node Started");
    }

    ~CameraProcessor() {
        if (net) {
            free_network_ptr(net);
        }
    }

    void spin() {
        while (ros::ok()) {
            ros::spinOnce();
            rate_.sleep();  // 프레임 제한 적용
        }
    }

private:
    ros::NodeHandle nh;
    ros::Subscriber imageSubscriber;
    ros::Publisher resultPublisher;
    network* net;
    std::vector<std::string> classes;
    ros::Rate rate_;  // 프레임 제한용 ROS Rate (초당 10 프레임)

    void loadClasses(const std::string& path) {
        std::ifstream ifs(path.c_str());
        std::string line;
        while (std::getline(ifs, line)) {
            classes.push_back(line);
        }
        ROS_INFO("Loaded %lu classes", classes.size());
    }

    void imageCallback(const sensor_msgs::ImageConstPtr& msg) {
        try {
            cv_bridge::CvImagePtr cvPtr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
            cv::Mat frame = cvPtr->image;

            if (frame.empty()) {
                ROS_ERROR("Received empty frame");
                return;
            }

            // YOLO 입력 변환 및 검출
            std::vector<cv::Rect> boxes;
            std::vector<int> classIds;
            std::vector<float> confidences;

            detectObjects(frame, boxes, classIds, confidences);

            // 검출된 객체 표시
            for (const auto& box : boxes) {
                cv::rectangle(frame, box, cv::Scalar(0, 255, 0), 1);
            }
            // 메시지 생성 및 발행
            project_ojakdong::DetectionResult resultMsg;
            // resultMsg.image에 처리된 이미지를 저장
            cv_bridge::CvImage processedMsg(std_msgs::Header(), "bgr8", frame);
            resultMsg.image = *processedMsg.toImageMsg();  // 처리된 이미지를 메시지에 포함

            resultMsg.class_ids = classIds;
            resultMsg.confidences = confidences;

            // 검출된 사각형 정보 추가
            for (const auto& box : boxes) {
                geometry_msgs::Polygon polygon;
                geometry_msgs::Point32 p1, p2, p3, p4;
                geometry_msgs::Point32 center;

                p1.x = box.x;
                p1.y = box.y;
                p2.x = box.x + box.width;
                p2.y = box.y;
                p3.x = box.x + box.width;
                p3.y = box.y + box.height;
                p4.x = box.x;
                p4.y = box.y + box.height;

                center.x = box.x + box.width / 2;
                center.y = box.y + box.height / 2;

                polygon.points.push_back(p1);
                polygon.points.push_back(p2);
                polygon.points.push_back(p3);
                polygon.points.push_back(p4);
                
                resultMsg.centers.push_back(center);  // 수정된 부분

                resultMsg.boxes.push_back(polygon);
            }
            resultPublisher.publish(resultMsg);
        } catch (const cv_bridge::Exception& e) {
            ROS_ERROR("cv_bridge Exception: %s", e.what());
        }
    }

    void detectObjects(const cv::Mat& frame, std::vector<cv::Rect>& boxes, std::vector<int>& classIds, std::vector<float>& confidences) {
        // YOLO 입력 변환
        image im = mat_to_image(frame);
        network_predict_image(net, im);

        int nboxes = 0;
        detection* dets = get_network_boxes(net, frame.cols, frame.rows, 0.5, 0.4, nullptr, 1, &nboxes, 0);

        // 박스 추출
        for (int i = 0; i < nboxes; ++i) {
            for (int j = 0; j < dets[i].classes; ++j) {
                if (classes[j] == "person" && dets[i].prob[j] > 0.5) {
                    int left = static_cast<int>((dets[i].bbox.x - dets[i].bbox.w / 2) * frame.cols);
                    int top = static_cast<int>((dets[i].bbox.y - dets[i].bbox.h / 2) * frame.rows);
                    int width = static_cast<int>(dets[i].bbox.w * frame.cols);
                    int height = static_cast<int>(dets[i].bbox.h * frame.rows);

                    boxes.emplace_back(left, top, width, height);
                    classIds.push_back(j);
                    confidences.push_back(dets[i].prob[j]);
                }
            }
        }

        // Non-Maximum Suppression 적용
        std::vector<int> indices;
        cv::dnn::NMSBoxes(boxes, confidences, 0.5, 0.4, indices);

        std::vector<cv::Rect> filteredBoxes;
        std::vector<int> filteredClassIds;
        std::vector<float> filteredConfidences;

        for (int idx : indices) {
            filteredBoxes.push_back(boxes[idx]);
            filteredClassIds.push_back(classIds[idx]);
            filteredConfidences.push_back(confidences[idx]);
        }

        boxes = filteredBoxes;
        classIds = filteredClassIds;
        confidences = filteredConfidences;

        free_detections(dets, nboxes);
    }

    image mat_to_image(const cv::Mat& mat) {
        int h = mat.rows;
        int w = mat.cols;
        int c = mat.channels();
        image im = make_image(w, h, c);
        for (int y = 0; y < h; ++y) {
            for (int x = 0; x < w; ++x) {
                for (int k = 0; k < c; ++k) {
                    im.data[k * w * h + y * w + x] = mat.at<cv::Vec3b>(y, x)[k] / 255.0;
                }
            }
        }
        return im;
    }
};

int main(int argc, char** argv) {
    ros::init(argc, argv, "camera_processor_node");
    CameraProcessor processor;
    processor.spin();
    return 0;
}

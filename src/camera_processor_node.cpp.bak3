#include <ros/ros.h>
#include <ros/package.h>
#include <sensor_msgs/Image.h>
#include <cv_bridge/cv_bridge.h>
#include <opencv2/opencv.hpp>
#include <opencv2/dnn.hpp>
#include "project_ojakdong/DetectionResult.h"
#include <fstream>

class CameraProcessor {
public:
    CameraProcessor() : rate_(15) {  // 초당 15 프레임 제한
        // YOLOv8 모델 초기화
        std::string packagePath = ros::package::getPath("project_ojakdong");
        std::string modelPath = packagePath + "/model/yolov8n.onnx";
        std::string classesPath = packagePath + "/model/coco.names";

        // OpenCV DNN 모델 로드
        net_ = cv::dnn::readNetFromONNX(modelPath);
        try {
            net_ = cv::dnn::readNetFromONNX(modelPath);
            net_.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);
            net_.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA);
        } catch (const cv::Exception& e) {
            ROS_WARN("CUDA 사용 실패, CPU로 전환합니다.");
            net_.setPreferableBackend(cv::dnn::DNN_BACKEND_DEFAULT);
            net_.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);
        }

        loadClasses(classesPath);

        // ROS 설정
        imageSubscriber = nh.subscribe("/usb_cam/image_raw", 1, &CameraProcessor::imageCallback, this);
        // imageSubscriber = nh.subscribe("/camera/rgb/image_raw", 1, &CameraProcessor::imageCallback, this);  //gazebo카메라
        resultPublisher = nh.advertise<project_ojakdong::DetectionResult>("/detection_result", 1);

        ROS_INFO("CameraProcessor Node Started with YOLOv8 nano (ONNX)");
    }

    void spin() {
        while (ros::ok()) {
            ros::spinOnce();
            rate_.sleep();
        }
    }

private:
    ros::NodeHandle nh;
    ros::Subscriber imageSubscriber;
    ros::Publisher resultPublisher;
    cv::dnn::Net net_;
    std::vector<std::string> classes;
    ros::Rate rate_;  // 프레임 제한용 ROS Rate (초당 15 프레임)

    void loadClasses(const std::string& path) {
        std::ifstream ifs(path.c_str());
        std::string line;
        while (std::getline(ifs, line)) {
            classes.push_back(line);
        }
        ROS_INFO("Loaded %lu classes", classes.size());
    }

    void imageCallback(const sensor_msgs::ImageConstPtr& msg) {
        try {
            cv_bridge::CvImagePtr cvPtr = cv_bridge::toCvCopy(msg, sensor_msgs::image_encodings::BGR8);
            cv::Mat frame = cvPtr->image;

            if (frame.empty()) {
                ROS_ERROR("Received empty frame");
                return;
            }

            // YOLOv8 추론 및 검출
            std::vector<cv::Rect> boxes;
            std::vector<int> classIds;
            std::vector<float> confidences;
            detectObjects(frame, boxes, classIds, confidences);

            // 검출된 객체 박스 그리기
            for (const auto& box : boxes) {
                cv::rectangle(frame, box, cv::Scalar(0, 255, 0), 1);
            }

            // 메시지 생성 및 발행
            project_ojakdong::DetectionResult resultMsg;
            cv_bridge::CvImage processedMsg(std_msgs::Header(), "bgr8", frame);
            resultMsg.image = *processedMsg.toImageMsg();
            resultMsg.class_ids = classIds;
            resultMsg.confidences = confidences;

            for (const auto& box : boxes) {
                geometry_msgs::Polygon polygon;
                geometry_msgs::Point32 p1, p2, p3, p4;
                geometry_msgs::Point32 center;

                p1.x = box.x;
                p1.y = box.y;
                p2.x = box.x + box.width;
                p2.y = box.y;
                p3.x = box.x + box.width;
                p3.y = box.y + box.height;
                p4.x = box.x;
                p4.y = box.y + box.height;

                center.x = box.x + box.width / 2;
                center.y = box.y + box.height / 2;

                polygon.points.push_back(p1);
                polygon.points.push_back(p2);
                polygon.points.push_back(p3);
                polygon.points.push_back(p4);

                resultMsg.centers.push_back(center);  // 중심 좌표 저장
                resultMsg.boxes.push_back(polygon);   // 검출된 박스 저장
            }

            resultPublisher.publish(resultMsg);

        } catch (const cv_bridge::Exception& e) {
            ROS_ERROR("cv_bridge Exception: %s", e.what());
        }
    }

    void detectObjects(const cv::Mat& frame, std::vector<cv::Rect>& boxes,
                   std::vector<int>& classIds, std::vector<float>& confidences) {
        cv::Mat blob = cv::dnn::blobFromImage(frame, 1 / 255.0, cv::Size(416, 416), cv::Scalar(), true, false);
        net_.setInput(blob);
        std::vector<cv::Mat> outputs;
        net_.forward(outputs, net_.getUnconnectedOutLayersNames());

        for (auto& output : outputs) {
            const int numDetections = output.size[2];
            for (int i = 0; i < numDetections; i++) {
                float confidence = output.at<float>(4, i);
                std::cout << "Confidence: " << confidence << std::endl;
            }
        }

        float confidenceThreshold = 0.5;
        float nmsThreshold = 0.4;

        // 결과 처리
        for (auto& output : outputs) {
            const int numDetections = output.rows;
            for (int i = 0; i < numDetections; i++) {
                float confidence = output.at<float>(i, 4);  // 4번째가 confidence
                if (confidence > confidenceThreshold) {
                    float* data = output.ptr<float>(i);
                    
                    int classId = std::max_element(data + 5, data + 85) - (data + 5);  // 클래스 확률 추출
                    float score = data[5 + classId];
                    
                    if (score > confidenceThreshold) {
                        int centerX = static_cast<int>(data[0] * frame.cols);
                        int centerY = static_cast<int>(data[1] * frame.rows);
                        int width = static_cast<int>(data[2] * frame.cols);
                        int height = static_cast<int>(data[3] * frame.rows);
                        int left = centerX - width / 2;
                        int top = centerY - height / 2;

                        boxes.emplace_back(left, top, width, height);
                        classIds.push_back(classId);
                        confidences.push_back(score);
                    }
                }
            }
        }

        // Non-Maximum Suppression 적용
        std::vector<int> indices;
        cv::dnn::NMSBoxes(boxes, confidences, confidenceThreshold, nmsThreshold, indices);

        std::vector<cv::Rect> filteredBoxes;
        std::vector<int> filteredClassIds;
        std::vector<float> filteredConfidences;

        for (int idx : indices) {
            filteredBoxes.push_back(boxes[idx]);
            filteredClassIds.push_back(classIds[idx]);
            filteredConfidences.push_back(confidences[idx]);
        }

        boxes = filteredBoxes;
        classIds = filteredClassIds;
        confidences = filteredConfidences;
    }

};

int main(int argc, char** argv) {
    ros::init(argc, argv, "camera_processor_node");
    CameraProcessor processor;
    processor.spin();
    return 0;
}
